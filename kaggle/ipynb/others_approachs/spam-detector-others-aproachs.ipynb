{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1 align=\"center\"> SPAM Detector: Text Classify Others Aproachs</h1>\n\n<img src=\"https://raw.githubusercontent.com/deepankarkotnala/Email-Spam-Ham-Classifier-NLP/master/images/email_spam_ham.png\" width=\"50%\" />\n\nCreated: 2020-09-15\n\nLast updated: 2020-09-15\n\nKaggle Kernel made by ðŸš€ <a href=\"https://www.kaggle.com/rafanthx13\"> Rafael Morais de Assis</a>\n\nThis is an initial kernel, in the future it will be filled with the theoretical part and more details about NLP"},{"metadata":{},"cell_type":"markdown","source":"## Table Of Contents (TOC) <a id=\"top\"></a>\n\n+ [Import Libs and DataSet](#index01) \n+ [Snippets](#index02)\n\n## Import Libs and DataSet <a id='index01'></a>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Configs\npd.options.display.float_format = '{:,.4f}'.format\nsns.set(style=\"whitegrid\")\nplt.style.use('seaborn')\nseed = 42\nnp.random.seed(seed)","execution_count":80,"outputs":[{"output_type":"stream","text":"/kaggle/input/sms-spam-collection-dataset/spam.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"file_path = '/kaggle/input/sms-spam-collection-dataset/spam.csv'\ndf = pd.read_csv(file_path, encoding='latin-1')\ndf = df[['v1', 'v2']]\ndf.columns = ['label', 'message']\n\nprint(\"DataSet = {} rows and {} columns\".format(df.shape[0], df.shape[1]))\ndf.head()","execution_count":81,"outputs":[{"output_type":"stream","text":"DataSet = 5572 rows and 2 columns\n","name":"stdout"},{"output_type":"execute_result","execution_count":81,"data":{"text/plain":"  label                                            message\n0   ham  Go until jurong point, crazy.. Available only ...\n1   ham                      Ok lar... Joking wif u oni...\n2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n3   ham  U dun say so early hor... U c already then say...\n4   ham  Nah I don't think he goes to usf, he lives aro...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>message</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Snippets <a id='index02'></a> <a href=\"#top\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" style=\"color:white; margin-left: 20px;\" data-toggle=\"popover\">Go to TOC</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\n\ndef time_spent(time0):\n    t = time.time() - time0\n    t_int = int(t) // 60\n    t_min = t % 60\n    if(t_int != 0):\n        return '{}min {:.3f}s'.format(t_int, t_min)\n    else:\n        return '{:.3f}s'.format(t_min)","execution_count":82,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import accuracy_score, f1_score\n\nthis_labels = ['HAM','SPAM']\nscoress = {}\n\ndef class_report(y_real, y_my_preds, name=\"\", labels=this_labels):\n    if(name != ''):\n        print(name,\"\\n\")\n    print(confusion_matrix(y_real, y_my_preds), '\\n')\n    print(classification_report(y_real, y_my_preds, target_names=labels))\n    scoress[name] = [accuracy_score(y_test, y_pred), f1_score(y_test, y_pred, average='macro')]\n    \n# Create DataFrame from Scores maded by 'class_report'\ndef create_df_fom_scores(scores=scoress):\n    return pd.DataFrame(data= scoress.values(),\n            columns=['acc','f1'],\n            index=scoress.keys())","execution_count":83,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Kaggle Course Strategie with Word2Vec"},{"metadata":{},"cell_type":"markdown","source":"### No Text PreProcessing Cleaning"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import spacy\n\n# Need to load the large model to get the vectors\nnlp_core = spacy.load('en_core_web_lg')","execution_count":84,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text = \"These vectors can be used as features for machine learning models.\"\n\ntext_nlp = nlp_core(text)\nprint(type(text_nlp))","execution_count":85,"outputs":[{"output_type":"stream","text":"<class 'spacy.tokens.doc.Doc'>\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Word2Vec\nwith nlp_core.disable_pipes():\n    vectors = np.array([ token.vector for token in  nlp_core(text)])","execution_count":86,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vectors.shape","execution_count":87,"outputs":[{"output_type":"execute_result","execution_count":87,"data":{"text/plain":"(12, 300)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"with nlp_core.disable_pipes():\n    X = np.array([nlp_core(text).vector for text in df.message.values])","execution_count":88,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":89,"outputs":[{"output_type":"execute_result","execution_count":89,"data":{"text/plain":"(5572, 300)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n\ny = df['label'].replace({'ham': 0, 'spam': 1}).values\n\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)","execution_count":90,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import LinearSVC\n\n# Set dual=False to speed up training, and it's not needed\nsvc = LinearSVC(random_state=42)#, dual=False, max_iter=10000)\nsvc.fit(x_train, y_train)\n\ny_pred = svc.predict(x_test)\n\nclass_report(y_test, y_pred, 'Kaggle Course: No text Cleaning Word2Vec spaCy with LinearSVC')","execution_count":91,"outputs":[{"output_type":"stream","text":"Kaggle Course: No text Cleaning Word2Vec spaCy with LinearSVC \n\n[[947  18]\n [ 14 136]] \n\n              precision    recall  f1-score   support\n\n         HAM       0.99      0.98      0.98       965\n        SPAM       0.88      0.91      0.89       150\n\n    accuracy                           0.97      1115\n   macro avg       0.93      0.94      0.94      1115\nweighted avg       0.97      0.97      0.97      1115\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### With Text PreProcessing Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\",\n\"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\",\n\"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\",\n\"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\",\n\"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\",\n\"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\",\n\"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\",\n\"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\",\n\"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n\"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\n\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\n\"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\",\n\"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\",\n\"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n\"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\",\n\"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\n\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\",\n\"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\",\n\"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\",\n\"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n\"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\",\n\"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\",\n\"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\",\n\"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n\"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\",\n\"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\",\n\"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" }\n\nmispell_dict = {'colour': 'color', 'centre': 'center', 'favourite': 'favorite', 'travelling': 'traveling',\n'counselling': 'counseling', 'theatre': 'theater', 'cancelled': 'canceled', 'labour': 'labor',\n'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', 'youtu ': 'youtube ', 'Qoura': 'Quora',\n'sallary': 'salary', 'Whta': 'What', 'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are',\n'howcan': 'how can', 'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I',\n'theBest': 'the best', 'howdoes': 'how does', 'Etherium': 'Ethereum', 'narcissit': 'narcissist',\n'bigdata': 'big data', '2k17': '2017', '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend',\n'airhostess': 'air hostess', \"whst\": 'what', 'watsapp': 'whatsapp', 'demonitisation': 'demonetization',\n'demonitization': 'demonetization', 'demonetisation': 'demonetization', 'pokÃ©mon': 'pokemon'}\n\ndef clean_contractions(text, mapping):\n    specials = [\"â€™\", \"â€˜\", \"Â´\", \"`\"]\n    for s in specials:\n        text = text.replace(s, \"'\")\n    text = ' '.join([mapping[t] if t in mapping else t for t in text.split(\" \")])\n    return text\n\ndef correct_spelling(x, dic):\n    for word in dic.keys():\n        x = x.replace(word, dic[word])\n    return x","execution_count":92,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords\nimport re\n\n# Stop Words in Python. Is better search in a 'set' structure\nstops = set(stopwords.words(\"english\"))  \n\ndef clean_text( text ):\n    # 1. Remove non-letters        \n    text = re.sub(\"[^a-zA-Z]\", \" \", text) \n    text = re.sub(r'[^\\w\\s]','',text, re.UNICODE)\n    # 2. Convert to lower case, split into individual words\n    text = text.lower().split()                                             \n    # 3. Remove stop words\n    meaningful_words = [w for w in text if not w in stops]   \n    # 4. Join the words back into one string separated by space.\n    return( \" \".join( meaningful_words )) \n\nfrom nltk.stem import WordNetLemmatizer\n\nlemmatizer = WordNetLemmatizer()\n\ndef lematizer(text):\n    text = [lemmatizer.lemmatize(token) for token in text.split(\" \")]\n    text = [lemmatizer.lemmatize(token, \"v\") for token in text]\n    text = \" \".join(text)\n    return text","execution_count":93,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clean_column = 'clean_message'\n\ndf[clean_column] = df['message'].apply(lambda x: clean_contractions(x, contraction_mapping))\n\ndf[clean_column] = df[clean_column].apply(lambda x: correct_spelling(x, mispell_dict))\n\ndf[clean_column] = df[clean_column].apply(clean_text)\n\ndf[clean_column] = df[clean_column].apply(lematizer)","execution_count":94,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df[clean_column].values\ny = df['label'].replace({'ham': 0, 'spam': 1})","execution_count":95,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with nlp_core.disable_pipes():\n    X_vec = np.array([nlp_core(text).vector for text in X])","execution_count":96,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.20, random_state=42)","execution_count":97,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import LinearSVC\n\n# Set dual=False to speed up training, and it's not needed\nsvc = LinearSVC(random_state=42)\nsvc.fit(x_train, y_train)\n\ny_pred = svc.predict(x_test)\n\nclass_report(y_test, y_pred, 'Kaggle Course: With text Cleaning Word2Vec spaCy with LinearSVC')","execution_count":98,"outputs":[{"output_type":"stream","text":"Kaggle Course: With text Cleaning Word2Vec spaCy with LinearSVC \n\n[[946  19]\n [ 22 128]] \n\n              precision    recall  f1-score   support\n\n         HAM       0.98      0.98      0.98       965\n        SPAM       0.87      0.85      0.86       150\n\n    accuracy                           0.96      1115\n   macro avg       0.92      0.92      0.92      1115\nweighted avg       0.96      0.96      0.96      1115\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## HSE Course NLP"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":99,"outputs":[{"output_type":"execute_result","execution_count":99,"data":{"text/plain":"  label                                            message  \\\n0   ham  Go until jurong point, crazy.. Available only ...   \n1   ham                      Ok lar... Joking wif u oni...   \n2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n3   ham  U dun say so early hor... U c already then say...   \n4   ham  Nah I don't think he goes to usf, he lives aro...   \n\n                                       clean_message  \n0  go jurong point crazy available bugis n great ...  \n1                              ok lar joke wif u oni  \n2  free entry wkly comp win fa cup final tkts st ...  \n3                u dun say early hor u c already say  \n4                nah think go usf life around though  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>message</th>\n      <th>clean_message</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n      <td>go jurong point crazy available bugis n great ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n      <td>ok lar joke wif u oni</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n      <td>free entry wkly comp win fa cup final tkts st ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n      <td>u dun say early hor u c already say</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n      <td>nah think go usf life around though</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\n\nXX = df['clean_message'].values\ny = df['label'].replace({'ham': 0, 'spam': 1})\n\nx_train, x_test, y_train, y_test = train_test_split(XX, y, test_size=0.20, random_state=42)\n\ntfidf_transformer = TfidfVectorizer(ngram_range=(1,2), max_df=0.9, min_df=5, token_pattern='(\\S+)')\ntfidf_transformer.fit(x_train)\n\nx_train_tfidf = tfidf_transformer.transform(x_train)\nx_test_tfidf  = tfidf_transformer.transform(x_test)","execution_count":100,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import LinearSVC\n\n# Set dual=False to speed up training, and it's not needed\nsvc = LinearSVC(random_state=42)#, dual=False, max_iter=10000)\nsvc.fit(x_train_tfidf, y_train)\n\ny_pred = svc.predict(x_test_tfidf)\n\nclass_report(y_test, y_pred, 'HSE NLP: TD-IDF LinearSVC no HyperTuned')","execution_count":101,"outputs":[{"output_type":"stream","text":"HSE NLP: TD-IDF LinearSVC no HyperTuned \n\n[[960   5]\n [ 13 137]] \n\n              precision    recall  f1-score   support\n\n         HAM       0.99      0.99      0.99       965\n        SPAM       0.96      0.91      0.94       150\n\n    accuracy                           0.98      1115\n   macro avg       0.98      0.95      0.96      1115\nweighted avg       0.98      0.98      0.98      1115\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Hyper Tuning LinearSVC"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import LinearSVC\n\ndef optimize(mx_train, my_train, my_hyper_params, hyper_to_search, hyper_search_name, cv=4, scoring='accuracy'):\n    \"\"\"search best param to unic one hyper param\n    @mx_train, @my_train = x_train, y_train of dataset\n    @my_hyper_params: dict with actuals best_params: start like: {}\n      => will be accumulated and modified with each optimization iteration\n      => example stater: best_hyper_params = {'random_state': 42, 'n_jobs': -1}\n    @hyper_to_search: dict with key @hyper_search_name and list of values to gridSearch:\n    @hyper_search_name: name of hyperparam\n    \"\"\"\n    if(hyper_search_name in my_hyper_params.keys()):\n        del my_hyper_params[hyper_search_name]\n    if(hyper_search_name not in hyper_to_search.keys()):\n        raise Exception('\"hyper_to_search\" dont have {} in dict'.format(hyper_search_name))\n        \n    t0 = time.time()\n        \n    rf = LinearSVC(**my_hyper_params)\n    \n    grid_search = GridSearchCV(estimator = rf, param_grid = hyper_to_search, \n      scoring = scoring, n_jobs = -1, cv = cv)\n    grid_search.fit(mx_train, my_train)\n    \n    print('took', time_spent(t0))\n    \n    data_frame_results = pd.DataFrame(\n        data={'mean_fit_time': grid_search.cv_results_['mean_fit_time'],\n        'mean_test_score_'+scoring: grid_search.cv_results_['mean_test_score'],\n        'ranking': grid_search.cv_results_['rank_test_score']\n         },\n        index=grid_search.cv_results_['params']).sort_values(by='ranking')\n    \n    print('The Best HyperParam to \"{}\" is {} with {} in {}'.format(\n        hyper_search_name, grid_search.best_params_[hyper_search_name], grid_search.best_score_, scoring))\n    \n    my_hyper_params[hyper_search_name] = grid_search.best_params_[hyper_search_name]\n    \n    \"\"\"\n    @@my_hyper_params: my_hyper_params appends best param find to @hyper_search_name\n    @@data_frame_results: dataframe with statistics of gridsearch: time, score and ranking\n    @@grid_search: grid serach object if it's necessary\n    \"\"\"\n    return my_hyper_params, data_frame_results, grid_search","execution_count":102,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_hyper_params = {'random_state': 42} # Stater Hyper Params","execution_count":103,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"search_hyper = {'penalty': ['l1', 'l2']}\n\nbest_hyper_params, results, last_grid_search = optimize(\n    x_train_tfidf, y_train, best_hyper_params, search_hyper, 'penalty')","execution_count":104,"outputs":[{"output_type":"stream","text":"took 2.856s\nThe Best HyperParam to \"penalty\" is l2 with 0.9854167505293412 in accuracy\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"search_hyper = {'loss': ['hinge', 'squared_hinge']}\n\nbest_hyper_params, results, last_grid_search = optimize(\n    x_train_tfidf, y_train, best_hyper_params, search_hyper, 'loss')","execution_count":105,"outputs":[{"output_type":"stream","text":"took 0.091s\nThe Best HyperParam to \"loss\" is squared_hinge with 0.9854167505293412 in accuracy\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"search_hyper = {'dual': [True, False]}\n\nbest_hyper_params, results, last_grid_search = optimize(\n    x_train_tfidf, y_train, best_hyper_params, search_hyper, 'dual')\n","execution_count":106,"outputs":[{"output_type":"stream","text":"took 0.082s\nThe Best HyperParam to \"dual\" is True with 0.9854167505293412 in accuracy\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"search_hyper = {'C': [0.8, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 20.0, 80.0]}\n\nbest_hyper_params, results, last_grid_search = optimize(\n    x_train_tfidf, y_train, best_hyper_params, search_hyper, 'C')\n","execution_count":107,"outputs":[{"output_type":"stream","text":"took 0.445s\nThe Best HyperParam to \"C\" is 1.4 with 0.9858653822930337 in accuracy\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_hyper_params","execution_count":108,"outputs":[{"output_type":"execute_result","execution_count":108,"data":{"text/plain":"{'random_state': 42,\n 'penalty': 'l2',\n 'loss': 'squared_hinge',\n 'dual': True,\n 'C': 1.4}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"search_hyper = {'max_iter': [1000, 16000]}\n\nbest_hyper_params, results, last_grid_search = optimize(\n    x_train_tfidf, y_train, best_hyper_params, search_hyper, 'max_iter')\n","execution_count":109,"outputs":[{"output_type":"stream","text":"took 0.080s\nThe Best HyperParam to \"max_iter\" is 1000 with 0.9858653822930337 in accuracy\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"search_hyper = {'tol': [0.00006, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0 ]}\n\nbest_hyper_params, results, last_grid_search = optimize(\n    x_train_tfidf, y_train, best_hyper_params, search_hyper, 'tol')\n","execution_count":110,"outputs":[{"output_type":"stream","text":"took 0.180s\nThe Best HyperParam to \"tol\" is 6e-05 with 0.9858653822930337 in accuracy\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import LinearSVC\n\nsvc = LinearSVC(random_state=42)\nsvc.fit(x_train_tfidf, y_train)\n\ny_pred = svc.predict(x_test_tfidf)\n\nclass_report(y_test, y_pred, 'HSE NLP: TD-IDF LinearSVC NO HyperTuned')","execution_count":112,"outputs":[{"output_type":"stream","text":"HSE NLP: TD-IDF LinearSVC NO HyperTuned \n\n[[960   5]\n [ 13 137]] \n\n              precision    recall  f1-score   support\n\n         HAM       0.99      0.99      0.99       965\n        SPAM       0.96      0.91      0.94       150\n\n    accuracy                           0.98      1115\n   macro avg       0.98      0.95      0.96      1115\nweighted avg       0.98      0.98      0.98      1115\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import LinearSVC\n\nsvc = LinearSVC(**best_hyper_params)\nsvc.fit(x_train_tfidf, y_train)\n\ny_pred = svc.predict(x_test_tfidf)\n\nclass_report(y_test, y_pred, 'HSE NLP: TD-IDF LinearSVC HyperTuned')","execution_count":113,"outputs":[{"output_type":"stream","text":"HSE NLP: TD-IDF LinearSVC HyperTuned \n\n[[959   6]\n [ 11 139]] \n\n              precision    recall  f1-score   support\n\n         HAM       0.99      0.99      0.99       965\n        SPAM       0.96      0.93      0.94       150\n\n    accuracy                           0.98      1115\n   macro avg       0.97      0.96      0.97      1115\nweighted avg       0.98      0.98      0.98      1115\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"create_df_fom_scores()","execution_count":114,"outputs":[{"output_type":"execute_result","execution_count":114,"data":{"text/plain":"                                                      acc     f1\nKaggle Course: No text Cleaning Word2Vec spaCy ... 0.9713 0.9391\nKaggle Course: With text Cleaning Word2Vec spaC... 0.9632 0.9204\nHSE NLP: TD-IDF LinearSVC no HyperTuned            0.9839 0.9645\nHSE NLP: TD-IDF LinearSVC NO HyperTuned            0.9839 0.9645\nHSE NLP: TD-IDF LinearSVC HyperTuned               0.9848 0.9668","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>acc</th>\n      <th>f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Kaggle Course: No text Cleaning Word2Vec spaCy with LinearSVC</th>\n      <td>0.9713</td>\n      <td>0.9391</td>\n    </tr>\n    <tr>\n      <th>Kaggle Course: With text Cleaning Word2Vec spaCy with LinearSVC</th>\n      <td>0.9632</td>\n      <td>0.9204</td>\n    </tr>\n    <tr>\n      <th>HSE NLP: TD-IDF LinearSVC no HyperTuned</th>\n      <td>0.9839</td>\n      <td>0.9645</td>\n    </tr>\n    <tr>\n      <th>HSE NLP: TD-IDF LinearSVC NO HyperTuned</th>\n      <td>0.9839</td>\n      <td>0.9645</td>\n    </tr>\n    <tr>\n      <th>HSE NLP: TD-IDF LinearSVC HyperTuned</th>\n      <td>0.9848</td>\n      <td>0.9668</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Spacy Text Classifyer Pipiline"},{"metadata":{"trusted":true},"cell_type":"code","source":"import spacy\n\n# Create an empty model\nnlp = spacy.blank(\"en\")\n\n# Create the TextCategorizer with exclusive classes and \"bow\" architecture\ntextcat = nlp.create_pipe(\n                \"textcat\",\n                config={\n                    \"exclusive_classes\": True,\n                    \"architecture\": \"bow\"})\n# Add the TextCategorizer to the empty model\nnlp.add_pipe(textcat)\n\n# Add NEGATIVE and POSITIVE labels to text classifier\ntextcat.add_label(\"ham\")\ntextcat.add_label(\"spam\")","execution_count":124,"outputs":[{"output_type":"execute_result","execution_count":124,"data":{"text/plain":"1"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from spacy.util import minibatch\nimport random\n\ndef train(model, train_data, optimizer, batch_size=8):\n    losses = {}\n    random.shuffle(train_data)\n    batches = minibatch(train_data, size=batch_size)\n    for batch in batches:\n        texts, labels = zip(*batch)\n        model.update(texts, labels, sgd=optimizer, losses=losses)\n    return losses","execution_count":125,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fix seed for reproducibility\nspacy.util.fix_random_seed(1)\nrandom.seed(1)\n\n# This may take a while to run!\noptimizer = nlp.begin_training()\ntrain_data = list(zip(train_texts, train_labels))\nlosses = train(nlp, train_data, optimizer)\nprint(losses['textcat'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text = \"This tea cup was full of holes. Do not recommend.\"\ndoc = nlp(text)\nprint(doc.cats)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(nlp, texts):\n    # Use the tokenizer to tokenize each input text example\n    docs = [nlp.tokenizer(text) for text in texts]\n\n    # Use textcat to get the scores for each doc\n    textcat = nlp.get_pipe('textcat')\n    scores, _ = textcat.predict(docs)\n\n    # From the scores, find the class with the highest score/probability\n    predicted_class = scores.argmax(axis=1)\n\n    return predicted_class","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"texts = val_texts[34:38]\npredictions = predict(nlp, texts)\n\nfor p, t in zip(predictions, texts):\n    print(f\"{textcat.labels[p]}: {t} \\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(model, texts, labels):\n    \"\"\" Returns the accuracy of a TextCategorizer model. \n    \n        Arguments\n        ---------\n        model: ScaPy model with a TextCategorizer\n        texts: Text samples, from load_data function\n        labels: True labels, from load_data function\n    \n    \"\"\"\n    # Get predictions from textcat model\n    predicted_class = predict(model, texts)\n\n    # From labels, get the true class as a list of integers (POSITIVE -> 1, NEGATIVE -> 0)\n    true_class = [int(each['cats']['POSITIVE']) for each in labels]\n\n    # A boolean or int array indicating correct predictions\n    correct_predictions = predicted_class == true_class\n\n    # The accuracy, number of correct predictions divided by all predictions\n    accuracy = correct_predictions.mean()\n\n    return accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = evaluate(nlp, val_texts, val_labels)\nprint(f\"Accuracy: {accuracy:.4f}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This may take a while to run! # DEMORA MUITO\nn_iters = 3\nfor i in range(n_iters):\n    losses = train(nlp, train_data, optimizer)\n    accuracy = evaluate(nlp, val_texts, val_labels)\n    print(f\"Loss: {losses['textcat']:.3f} \\t Accuracy: {accuracy:.3f}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}